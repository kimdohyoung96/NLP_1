# -*- coding: utf-8 -*-
"""[대학원]고급자연어처리

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AQlnNyBSLDCAZVDBVCT8_9K3WDfPQyoc
"""

from google.colab import drive
drive.mount('/content/gdrive/')

import pandas as pd

import os
import re
import time

import numpy as np

# 1. 주어진 데이터 load
df = pd.read_csv("/content/gdrive/MyDrive/nlp/ratings_mini.txt", sep="\t", encoding="utf8")

df

# 2. 전체 데이터셋을 positive review/negative review로 나눈 후 각 개수 출력

# 1 = positive
# 0 = negative

df["label"].value_counts()

!pip install konlpy

# 3. positive review/negative review 형태소 분석 후 각 분류의 리뷰들을 형태소들의 출현 빈도를 counting

from konlpy.tag import Kkma

# 형태소 분석기

kkma = Kkma()

neg_df = df["document"]

pos_pos = [] #긍정 리뷰 형태소 분석 용
neg_pos = [] #부정 리뷰 형태소 분석 용

pos_df = df[df["label"] == 1]
neg_df = df[df['label'] == 0]

for doc in pos_df["document"]:
  pos_pos.append(kkma.pos(doc))
for doc in neg_df["document"]:
  neg_pos.append(kkma.pos(doc))

# 데이터를 평평하게 만들기
flat_data = [item for sublist in pos_pos for item in sublist]

# DataFrame으로 변환
pp_df = pd.DataFrame(flat_data, columns=['단어', '품사'])

# 데이터를 평평하게 만들기
flat_data = [item for sublist in neg_pos for item in sublist]

# DataFrame으로 변환
np_df = pd.DataFrame(flat_data, columns=['단어', '품사'])

pp_df['품사'].value_counts()

np_df['품사'].value_counts()

# 4. 긍정단어와 부정단어 추출

p_df = pd.concat([pp_df, np_df])

p_df

# 각 데이터 값의 빈도를 계산
value_counts = p_df['단어'].value_counts()

# 빈도가 10 이상인 데이터만 선택
min_frequency = 10
selected_values = value_counts[value_counts >= min_frequency].index

pos_word = []
neg_word = []

for word in selected_values:
  p_count = len(pp_df[pp_df["단어"] == word])
  n_count = len(np_df[np_df["단어"] == word])

  per = p_count / (p_count + n_count)
  if per >= 0.9:
    pos_word.append(word)
  elif per <= 0.1:
    neg_word.append(word)

pos_word

neg_word





